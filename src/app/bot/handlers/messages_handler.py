import uuid
import logging
from datetime import datetime
from fastapi import Depends
from aiogram import Router, F
from aiogram.types import Message
from dependency_injector.wiring import inject, Provide
from aiogram.types import (
    Message,
    CallbackQuery,
)

from src.app.integrations.redis import RedisService
from src.app.core.containers import Container
from src.app.integrations.rmq.publisher import publish_to_queue

from src.app.bot.keyboards.main_keyboards import get_model_keyboard
from src.app.services.bot_functions import (
    log_interaction,
    check_rate_limit,
    set_model,
    get_model,
    is_response_processing,
)

logger = logging.getLogger(__name__)


router = Router(name="Messages")


@router.callback_query(F.data.startswith("model_"))
async def model_selection(callback: CallbackQuery):
    model: str = callback.data.split("_")[1]

    if model == "chatgpt":
        str_model = "ChatGPT"
    elif model == "yandexgpt":
        str_model = "YandexGPT"
    else:
        return

    await set_model(callback.from_user.id, model)
    await callback.message.answer(
        f"*–í—ã –≤—ã–±—Ä–∞–ª–∏ –º–æ–¥–µ–ª—å: {str_model}* ü§ñ\n–¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏ —Å–≤–æ–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –ø–∏—Ç–∞–Ω–∏—é\."
    )

    await log_interaction(
        callback.from_user.id,
        callback.from_user.username or "",
        f"–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ {model}",
        f"–ú–æ–¥–µ–ª—å {model} –≤—ã–±—Ä–∞–Ω–∞.",
    )


@router.message()
async def handle_message(
    message: Message,
):
    if not await check_rate_limit(message.from_user.id):
        await message.answer(
            "*–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤\!*\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ ‚è≥"
        )
        return

    user_id: str = str(message.from_user.id)
    chat_id: str = str(message.chat.id)
    user_query: str = str(message.text)
    model: str = await get_model(user_id)

    if isinstance(model, bytes):
        model = model.decode("utf-8")
    elif model is None:
        await message.answer(
            "_–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã:_",
            reply_markup=get_model_keyboard(),
        )
        return

    if await is_response_processing(user_id):
        await message.answer(
            "*–ó–∞–ø—Ä–æ—Å –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ\.\.\.* ‚è≥\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –Ω–æ–≤–æ–≥–æ\."
        )
        return

    waiting_message = await message.answer("*–û–∂–∏–¥–∞–π—Ç–µ –æ—Ç–≤–µ—Ç\.\.\. ‚è≥*")
    waiting_message_id = waiting_message.message_id

    task = {
        "type": "llm_task",
        "task_id": str(uuid.uuid4()),
        "user_id": user_id,
        "chat_id": chat_id,
        "user_query": str(message.text),
        "model": str(model) if model else None,
        "waiting_message_id": waiting_message_id,
        "timestamp": datetime.now().isoformat(),
    }

    logger.debug(f"Prepared task: {task}")
    await publish_to_queue(task)

    await log_interaction(
        message.from_user.id,
        message.from_user.username or "",
        user_query,
        response_text="",
    )
